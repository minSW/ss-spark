<!-- 
/ss-spark/week{#}/minsw/README.md

# Week {#}

## What I've Learned 🙂

## On/Offline
> 2021.00.00

-->


# Week 0


## What I've Learned 🙂
[ Part 1 빅데이터와 스파크 간단히 살펴보기 ]
- CHAPTER 1 아파치 스파크란
  - [블로그](https://minsw.github.io/2021/01/20/Spark-The-Definitive-Guide-1%EC%9E%A5/)
- CHAPTER 2 스파크 간단히 살펴보기
  - [블로그](https://minsw.github.io/2021/01/24/Spark-The-Definitive-Guide-2%EC%9E%A5/)


## Online (Zoom)
> 2021.01.21

<img width="500" alt="week0" src="https://user-images.githubusercontent.com/26691216/105628125-59c67280-5e7e-11eb-9a8a-fae830dd56c6.png"/>


- Spark 버전은?
  - 메이저 버전이 다르면 차이가 좀 있어서, 책 기준으로 2 버전 권장
- Spark 언어는?
  - PySpark / Spark(Scala) 중 각자 원하는대로 => 나는 *Spark (Scala)*
- 스터디 진행방법은?
  - 초반은 각자 공부해서 정리하는 식으로
  - 파트 4 들어가기전에 데이터셋을 정해서 분석하는 방향이 좋을 듯
    - 파트 4 - 운영용 어플리케이션 : 하둡클러스터랑 연결 + 어플리케이션 (운영 잡은 배치 잡 / 성능 튜닝)
    - 데이터 셋이 큰 친구들로 ~
  - => 정리된 진행 방식은 [README.md](https://github.com/strange-study/ss-spark/blob/main/README.md) 참고
