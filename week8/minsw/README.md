<!-- 
/ss-spark/week{#}/minsw/README.md

# Week {#}

## What I've Learned 🙂

## On/Offline
> 2021.00.00

-->


# Week 8


## What I've Learned 🙂

[ Part 4 운영용 애플리케이션 ]

- CHAPTER 15 클러스터에서 스파크 실행하기

<br/>

### CHAPTER 15
> 구조적 API로 정의한 논리적 연산
>
> -> 논리적 실행계획으로 분해
>
> -> 물리적 실행계획으로 변환 (RDD 작업 단위)

- 스파크 애플리케이션 아키텍쳐 - 개념 정리
  - 물리적 머신에 연결되는 개념)
    - **클러스터 매니저** (ex. 스탠드얼론, 아파치 메소스, YARN)
    - '드라이버(마스터)' 노드 & '워커' 노드
    - 클러스터 매니저의 프로세스 ● ○
  - 스파크 애플리케이션 프로세스에 연결되는 개념)
    - 스파크 드라이버 & 스파크 익스큐터
    - 드라이버 프로세스, 익스큐터 프로세스 ◼︎ ◻︎
- 생애주기 (외부)
  - 클라이언트 요청 -> 시작 -> ('스파크 클러스터' 완성) -> 실행 -> 완료
- 생애주기 (내부)
  - SparkSession (2.x) : SparkContext, SQLContext (1.x) 포함
    ```scala
    val spark = SparkSession.builder()...getOrCreate() // SparkSession 생성
    val sc = SparkSession.sparkContext // SparkContext 접근 (for 저수준 API 사용)
    ```
  - 잡, 스테이지, 태스크
    - 1 스파크 애플리케이션 = N * 스파크 잡 (보통 1액션 -> 1잡)
    - 1 스파크 **잡** = n * **스테이지** = n * (m * 동일 연산 **태스크**)
    - 태스크는 데이터 단위(파티션)에 적용되는 연산 단위 (1파티션 -> 1태스크)
- 실행계획 분석법
- p.386 "파이프라이닝 기법은 노드 간의 데이터 이동 없이 각 노드가 데이터를 직접 공급할 수 있는 연산만 모아 **태스크의 단일 스테이지로 만듭니다**"
  - 단일 태스크를 가지는 '스테이지를 뜻하는지? '스테이지'와는 별개의 의미로 사용했는지?
  - 책의 예제처럼 map -> filter -> map 순의 경우, 개별 레코드 1당 1 태스크?
- p.387 셔플 결과 저장 (ex. reduceByKey() 연산 수행 시)
  - 데이터 전송이 필요한 **소스 태스크** 먼저 수행하고, 해당 태스크의 스테이지 수행 동안 셔플 파일을 로컬 디스크에 기록
  - 잡 실패 시 => 소스 태스크 재실행 필요 X
  - 사전 셔플 스테이지(pre-shuffle stage) 를 통해 자동 최적화 가능


## Online (WhaleON)
> 2021.04.01

진행 후 추가
