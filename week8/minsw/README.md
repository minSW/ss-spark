<!-- 
/ss-spark/week{#}/minsw/README.md

# Week {#}

## What I've Learned 🙂

## On/Offline
> 2021.00.00

-->


# Week 8


## What I've Learned 🙂

[ Part 4 운영용 애플리케이션 ]

- CHAPTER 15 클러스터에서 스파크 실행하기

<br/>

### CHAPTER 15
> 구조적 API로 정의한 논리적 연산
>
> -> 논리적 실행계획으로 분해
>
> -> 물리적 실행계획으로 변환 (RDD 작업 단위)

- 스파크 애플리케이션 아키텍쳐 - 개념 정리
  - 물리적 머신에 연결되는 개념)
    - **클러스터 매니저** (ex. 스탠드얼론, 아파치 메소스, YARN)
    - '드라이버(마스터)' 노드 & '워커' 노드
    - 클러스터 매니저의 프로세스 ● ○
  - 스파크 애플리케이션 프로세스에 연결되는 개념)
    - 스파크 드라이버 & 스파크 익스큐터
    - 드라이버 프로세스, 익스큐터 프로세스 ◼︎ ◻︎
- 생애주기 (외부)
  - 클라이언트 요청 -> 시작 -> ('스파크 클러스터' 완성) -> 실행 -> 완료
- 생애주기 (내부)
  - SparkSession (2.x) : SparkContext, SQLContext (1.x) 포함
    ```scala
    val spark = SparkSession.builder()...getOrCreate() // SparkSession 생성
    val sc = SparkSession.sparkContext // SparkContext 접근 (for 저수준 API 사용)
    ```
  - 잡, 스테이지, 태스크
    - 1 스파크 애플리케이션 = N * 스파크 잡 (보통 1액션 -> 1잡)
    - 1 스파크 **잡** = n * **스테이지** = n * (m * 동일 연산 **태스크**)
    - 태스크는 데이터 단위(파티션)에 적용되는 연산 단위 (1파티션 -> 1태스크)
- 실행계획 분석법
- p.386 "파이프라이닝 기법은 노드 간의 데이터 이동 없이 각 노드가 데이터를 직접 공급할 수 있는 연산만 모아 **태스크의 단일 스테이지로 만듭니다**"
  - 단일 태스크를 가지는 '스테이지를 뜻하는지? '스테이지'와는 별개의 의미로 사용했는지?
  - 책의 예제처럼 map -> filter -> map 순의 경우, 개별 레코드 1당 1 태스크?
- p.387 셔플 결과 저장 (ex. reduceByKey() 연산 수행 시)
  - 데이터 전송이 필요한 **소스 태스크** 먼저 수행하고, 해당 태스크의 스테이지 수행 동안 셔플 파일을 로컬 디스크에 기록
  - 잡 실패 시 => 소스 태스크 재실행 필요 X
  - 사전 셔플 스테이지(pre-shuffle stage) 를 통해 자동 최적화 가능


## Online (WhaleON)
> 2021.04.01

<img width="500" alt="week8" src="https://user-images.githubusercontent.com/26691216/115326349-1bfc9000-a1c8-11eb-96e3-bdb768e446ad.png">

- minsw
  - "태스크의 단일 스테이지로 만듭니다." => ?
    - 그냥 또 번역상의 이슈인 듯
- myeongki
  - 재밌게본 부분은 8주차 리드미 참고
- jin5335
  - 클러스터에서 어떻게 실행이됐고, 왜 분산 처리 클러스터라고 말하는지 여기 챕터에서 잘 이해하게 설명해준거같다
  - 클라이언트 모드 (외부에서 스파크..) / 클러스터 모드 (직접 관리) => 생소한 부분이라 재밌게 읽었다
    - 클러스터 (hadoop, spark 관리)
    - 클라이언트 : 스파크가 애플리케이션을 실행하기 위해 스파크의 드라이버 프로세스 (for 어플리케이션 관리)/익스큐터 프로세스
- 스파크의 드라이버 프로세스 (for 어플리케이션 관리)의 위치에따라 모드가 바뀐다
  - 제출 자체는 둘다 외부인데
  - 스파크 드라이버 프로세스가 외부에 떠있냐 (클라이언트 모드), 클러스터 내부에 있냐 차이
    - 개인적으로 클라이언트 모드는 별로인듯
    - Why? => 스파크 관리 드라이버 프로세스가 클라쪽에 떠있으면 통신을 계속 해야하니까... (익스큐터 결과가 계속 드라이버로 보내야되는데 그걸 자꾸 외부랑 통신해야만 하니까)
    - 클러스터 내부에잇으면 통신도 내부에서만 하고, 결과만 클라한테 보내니까 good

### 다음 스터디 방향?
- 1안. spark application 을 짜보자가 편하면
  - python 데이터 전처리를 하는데 (like 캐글)
  - 그 전처리를 스파크에서 해보는게 어떤가
- 2안. hdfs에 어딘가에 적재하고, 시간별로 스트림으로 땡겨와서, 그 데이터를 스파크로 처리한 뒤 정제된 데이터를 시각화 사이트로 보여주는 프로젝트를해도 재밌을 듯
  - 주제는 프리
  - 크롤링 + 데이터 저장 파이프라인 + 스파크 어플리케이션 짜고 + 시각화 툴
- 그럼 주제를 위한 open api 가 있는가?
  - 사용자가 뭔갈 사용하고있는거에대해서 개인화해서 실시간으로 뽑는 api가 없는듯..
  - just 질의 등
- 크롤링을 통해서 (주기적 scheduling) 유의미한 데이터를 뽑고, 정제하고, 앱으로 쏴주는
  - 뭐 일단 앱으로 띄우기만해도 시각화가 아닌가
  - 어떤 데이터를 뽑을거며, 어떤 유의미한 데이터를 창출할 것이냐 (기획측면)
- 아이디어 ("나라면, 이런게 있으면 좋겠다")
  - myeongki) 뉴스같은거 hot 10개, 매일매일
    - 정제의 기준은 우리가해야되지만
    - 뉴스에서 가장 많이나오는 '단어' 로 핫키워드 생성하기
    - 또는 1안을 따라가듯이 캐글데이터로
    - 시각화라던지 rest api뽑고는 
    - "스파크 어플리케이션 짜고 + 시각화 툴" 에 집중하고
    - 그 다음 필요하다면 "데이터 저장 파이프라인" 으로 확장
    - 이렇다면 사실 고정데이터로도 유의미 데이터를 뽑는 것도 좋지 않을까
  - 결론으로 둘 중 하나가 좋을 듯
    - 데이터 저장 파이프라인 + 스파크 어플리케이션
    - 스파크 어플리케이션 짜고 + 시각화 툴 (고정 데이터)
- "캐글데이터로 고정데이터로 재밌는, 유의미한 값을 뽑는것까지만해도 유의미하지 않나" 라는 의견
- 어쨌든 어플리케이션을 잘 만들어야 거기다가 얹어가는것 아니겠는가
- myeongki) 라이프사이클이 제일재밌었다 ㅋㅋㅋㅋㅋ