# 4주차 정리

## 12장
- RDD는 불변성을 가지며 병렬로 처리할 수 있는 파티셔닝된 레코드의 모음.
- DataFrame의 각 레코드는 스키마를 알고 있는 필드로 구성된 구조화된 로우인 반면, RDD의 레코드는 그저 프로그래머가 선택하는 자바, 스칼라, 파이썬의 객체일 뿐이다.
- RDD를 사용시에 바퀴를 다시 발명해야하는 수고가 따른다.. 그러므로 스파크의 구조적 api를 사용할 것을 강력하게 권고한다.(최적화를 수작업으로 진행해야한다.)
- RDD는 DataFrame api에서 최적화된 물리적 실행 계획을 만드는 데 대부분 사용된다.
- RDD 역시 분산 환경에서 데이터를 다루는 데 필요한 지연 처리 방식의 트랜스포메이션과 즉시 실행방식의 액션을 제공.
- 로우라는 개념이 없기 때문에 구조적 api에서 제공하는 여러 함수를 사용하지 못함. -> 수동처리 필요
- 파이썬을 사용해 RDD를 다루는 경우에 오버해드 발생 : 직렬화 된 데이터를 파이썬에서 처리하고 다시 직렬화하여 자바 가상 머신에 반환 !! 오버해드 발생..
- 로컬 컬렉션으로 RDD만들기 -> sparkContext의 parallelize를 통하여.. 만들 수 있다.
- 체크포인팅 dataFrame api에서 사용할 수 없는 기능 중 하나이다. RDD를 디스크에 저장하는 방식이다.(캐싱과 유사-> 반복적인 연산 수행 시 매우 유용) -> 다시 데이터 소스를 계산하지 않고 디스크에 저장된 것을 불러오기
- 